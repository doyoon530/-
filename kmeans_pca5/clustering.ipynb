{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래는 지정한 폴더의 엑셀파일들을 불러오는 전처리 코드입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 현재 스크립트의 경로 가져오기\n",
    "current_folder = os.getcwd()\n",
    "\n",
    "folder_path = os.path.join(current_folder, 'train')\n",
    "file_names = [file_name for file_name in os.listdir(folder_path) if file_name.endswith('.xlsx') and (not file_name.startswith(\"~$\"))]\n",
    "print(file_names)\n",
    "\n",
    "data_points = []  # 섹션 구분 없이 모든 데이터를 저장할 리스트\n",
    "\n",
    "def process_files_in_folder():\n",
    "    global data_points\n",
    "\n",
    "    section_files = [file_name for file_name in file_names if not file_name.startswith(\"~$\")]\n",
    "    for file_name in section_files:\n",
    "        print(file_name)\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        try:\n",
    "            df = pd.read_excel(file_path, header=0, engine='openpyxl')\n",
    "\n",
    "            value_xx = df[\"xx\"].tolist() if \"xx\" in df.columns else df[0].tolist()\n",
    "            value_xy = df[\"xy\"].tolist() if \"xy\" in df.columns else df[1].tolist()\n",
    "            value_xz = df[\"xz\"].tolist() if \"xz\" in df.columns else df[2].tolist()\n",
    "            value_yx = df[\"yx\"].tolist() if \"yx\" in df.columns else df[3].tolist()\n",
    "            value_yy = df[\"yy\"].tolist() if \"yy\" in df.columns else df[4].tolist()\n",
    "            value_yz = df[\"yz\"].tolist() if \"yz\" in df.columns else df[5].tolist()\n",
    "            value_zx = df[\"zx\"].tolist() if \"zx\" in df.columns else df[6].tolist()\n",
    "            value_zy = df[\"zy\"].tolist() if \"zy\" in df.columns else df[7].tolist()\n",
    "            value_zz = df[\"zz\"].tolist() if \"zz\" in df.columns else df[8].tolist()\n",
    "\n",
    "            for xx, xy, xz, yx, yy, yz, zx, zy, zz in zip(value_xx, value_xy, value_xz,\n",
    "                                                           value_yx, value_yy, value_yz,\n",
    "                                                           value_zx, value_zy, value_zz):\n",
    "                data_points.append((xx, xy, xz, yx, yy, yz, zx, zy, zz))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"\\n\\n\\nError reading file '{file_name}': {e}\\n\\n\\n\")\n",
    "\n",
    "process_files_in_folder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pca차원축소를 진행하는 코드입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# 섹션 이름 리스트\n",
    "sections = [\"front\", \"left_side\", \"right_side\", \"left_up\", \"left_down\", \"right_up\", \"right_down\", \"unknown\"]\n",
    "\n",
    "# 데이터 처리\n",
    "results = {}\n",
    "\n",
    "# 데이터 포인트를 2D 배열로 변환\n",
    "data_points = np.array(data_points)\n",
    "\n",
    "# 데이터 포인트가 2D 배열임을 확인\n",
    "if len(data_points.shape) == 1:\n",
    "    data_points = data_points.reshape(-1, 9)  # 9차원 데이터\n",
    "\n",
    "print(\"데이터 포인트 재구성 후 형태:\", data_points.shape)\n",
    "\n",
    "# PCA를 사용하여 데이터를 5차원으로 축소\n",
    "pca = PCA(n_components=5)  # n_components를 5으로 변경\n",
    "data_3d = pca.fit_transform(data_points)\n",
    "\n",
    "print(\"설명된 분산 비율:\", pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_df = pd.DataFrame(data_3d, columns=['PC1', 'PC2', 'PC3', 'PC4', 'PC5'])\n",
    "pca_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# DataFrame 생성\n",
    "pca_df = pd.DataFrame(data_3d, columns=['PC1', 'PC2', 'PC3', 'PC4', 'PC5'])\n",
    "\n",
    "# DataFrame을 XLSX 파일로 저장\n",
    "pca_df.to_excel(\"pca_data.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 클러스터링 코드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래는 xx xy xz yx yy yz zx zy zz의 9차원 데이터를 2차원데이터로 변환하여 k-means 클러스터링한 다음 로지스틱회귀를 통해 예측 모델을 만드는 코드입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 클러스터와 섹션 매핑 실험\n",
    "cluster_section_mapping = {0: 'right_down', 1: 'right_up', 2: 'front', 3: 'right_side', 4: 'unknown', 5: 'left_down', 6: 'left_side', 7: 'left_up' }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# 클러스터링 결과를 일관성 있게 만들기 위한 랜덤 시드 고정\n",
    "np.random.seed(42)\n",
    "\n",
    "# K-means 클러스터링 수행\n",
    "num_clusters = 8\n",
    "kmeans = KMeans(n_clusters=num_clusters, init=\"k-means++\")\n",
    "kmeans.fit(data_3d)\n",
    "labels = kmeans.labels_\n",
    "\n",
    "print(\"클러스터 레이블:\", labels)\n",
    "\n",
    "# 클러스터 레이블에 대응하는 섹션 이름 리스트 생성\n",
    "mapped_sections = [cluster_section_mapping[cluster_label] for cluster_label in labels]\n",
    "\n",
    "# 모델 학습 및 평가\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_3d, mapped_sections, test_size=0.2, random_state=42)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"정확도:\", accuracy)\n",
    "\n",
    "# F1 점수 계산\n",
    "f1 = f1_score(y_test, predictions, average='weighted')  # weighted F1 score를 계산\n",
    "\n",
    "print(\"F1 점수:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# 각 클러스터에 속한 데이터 포인트 수 계산\n",
    "cluster_counts = Counter(labels)\n",
    "\n",
    "# 클러스터 레이블을 오름차순으로 정렬\n",
    "sorted_cluster_labels = sorted(cluster_counts.keys())\n",
    "\n",
    "# 클러스터별 데이터 포인트 수 출력\n",
    "for cluster_label in sorted_cluster_labels:\n",
    "    count = cluster_counts[cluster_label]\n",
    "    section = cluster_section_mapping.get(cluster_label, 'unknown')\n",
    "    print(f\"클러스터 {cluster_label} ({section}): {count}개 데이터 포인트\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 클러스터의 중심점 얻기\n",
    "cluster_centers = kmeans.cluster_centers_\n",
    "\n",
    "# 클러스터의 범위(반경) 설정 (예: 0.5 단위)\n",
    "cluster_radius = 0.5\n",
    "\n",
    "# 클러스터 범위 설정 및 출력\n",
    "cluster_ranges = {}\n",
    "for cluster_label, center in enumerate(cluster_centers):\n",
    "    # 각 클러스터의 중심점을 기준으로 클러스터 범위 설정\n",
    "    cluster_range = [center - cluster_radius, center + cluster_radius]\n",
    "    cluster_ranges[cluster_label] = cluster_range\n",
    "\n",
    "# 클러스터의 범위 출력\n",
    "for cluster_label, cluster_range in cluster_ranges.items():\n",
    "    section = cluster_section_mapping.get(cluster_label, 'unknown')\n",
    "    print(f\"클러스터 {section}의 범위:\")\n",
    "    print(f\"최소 값: {cluster_range[0]}\")\n",
    "    print(f\"최대 값: {cluster_range[1]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# 원래 데이터포인트와 PCA 축소된 데이터를 결합\n",
    "pca_df = pd.DataFrame(data_3d, columns=['PC1', 'PC2', 'PC3', 'PC4', 'PC5'])\n",
    "\n",
    "# 원래 데이터포인트에서 섹션 정보를 가져옴\n",
    "pca_df['Section'] = mapped_sections\n",
    "\n",
    "# 섹션 이름 변경\n",
    "pca_df['Section'] = pca_df['Section'].replace({\n",
    "    'front': 'IO (1)',\n",
    "    'left_side': 'LMO (2)',\n",
    "    'right_side': 'RMO (3)',\n",
    "    'left_up': 'LUMC (4)',\n",
    "    'left_down': 'LWMC (5)',\n",
    "    'right_up': 'RUMC (6)',\n",
    "    'right_down': 'RWMC (7)',\n",
    "    'unknown': 'unknown'\n",
    "})\n",
    "\n",
    "# 데이터 시객화\n",
    "fig = px.scatter_3d(pca_df, x='PC1', y='PC2', z='PC3', color='Section', title='PCA 3D 시각화',\n",
    "                    category_orders={'Section': ['IO (1)', 'LMO (2)', 'RMO (3)', 'LUMC (4)', 'LWMC (5)', 'RUMC (6)', 'RWMC (7)', 'unknown']})\n",
    "\n",
    "# 그래프의 크기와 해상도 조절\n",
    "fig.update_layout(width=800, height=600)\n",
    "\n",
    "# 글꼴 크기 조절\n",
    "fig.update_layout(\n",
    "    font=dict(\n",
    "        size=20  # 글꼴 크기를 20으로 설정\n",
    "    )\n",
    ")\n",
    "\n",
    "# x,y,z 축 숫자 레이블의 글꼴 크기 설정\n",
    "fig.update_layout(scene=dict(\n",
    "    xaxis=dict(\n",
    "        title_font=dict(size=17),\n",
    "        tickfont=dict(size=10),   # x 축 숫자 레이블의 글꼴 크기를 설정\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title_font=dict(size=17),\n",
    "        tickfont=dict(size=10),   # y 축 숫자 레이블의 글꼴 크기를 설정\n",
    "    ),\n",
    "    zaxis=dict(\n",
    "        title_font=dict(size=17),\n",
    "        tickfont=dict(size=10),   # z 축 숫자 레이블의 글꼴 크기를 설정\n",
    "    )  \n",
    "))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# 원래 데이터포인트와 PCA 축소된 데이터를 결합\n",
    "pca_df = pd.DataFrame(data_3d, columns=['PC1', 'PC2', 'PC3', 'PC4', 'PC5'])\n",
    "\n",
    "# 원래 데이터포인트에서 섹션 정보를 가져옴\n",
    "pca_df['Section'] = mapped_sections\n",
    "\n",
    "# 섹션 이름 변경\n",
    "pca_df['Section'] = pca_df['Section'].replace({\n",
    "    'front': 'IO (1)',\n",
    "    'left_side': 'LMO (2)',\n",
    "    'right_side': 'RMO (3)',\n",
    "    'left_up': 'LUMC (4)',\n",
    "    'left_down': 'LWMC (5)',\n",
    "    'right_up': 'RUMC (6)',\n",
    "    'right_down': 'RWMC (7)',\n",
    "    'unknown': 'unknown'\n",
    "})\n",
    "\n",
    "# 데이터 시각화 (2D 산점도)\n",
    "fig = px.scatter(pca_df, x='PC1', y='PC2', color='Section', title='PCA 2D 시각화',\n",
    "                category_orders={'Section': ['IO (1)', 'LMO (2)', 'RMO (3)', 'LUMC (4)', 'LWMC (5)', 'RUMC (6)', 'RWMC (7)', 'unknown']})\n",
    "\n",
    "# 그래프의 크기와 해상도 조절\n",
    "fig.update_layout(width=800, height=600)\n",
    "\n",
    "fig.update_layout(\n",
    "    font=dict(\n",
    "        size=20  # 글꼴 크기를 20으로 설정\n",
    "    )\n",
    ")\n",
    "\n",
    "# x,y 축 숫자 레이블의 글꼴 크기 설정\n",
    "fig.update_layout(scene=dict(\n",
    "    xaxis=dict(\n",
    "        title_font=dict(size=17),\n",
    "        tickfont=dict(size=10),   # x 축 숫자 레이블의 글꼴 크기를 설정\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title_font=dict(size=17),\n",
    "        tickfont=dict(size=10),   # y 축 숫자 레이블의 글꼴 크기를 설정\n",
    "    )\n",
    "))\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 검증 코드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래는 클러스터링이 제대로 됬는지 지정한 폴더의 엑셀파일들을 넣어보며 정확도를 검증하는 코드입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "result_show = \"\"\n",
    "\n",
    "# 현재 스크립트의 경로 가져오기\n",
    "current_folder = os.getcwd()\n",
    "\n",
    "folder_path = os.path.join(current_folder, 'train')\n",
    "\n",
    "# 엑셀 파일 목록 얻어오기\n",
    "excel_files = [file_name for file_name in os.listdir(folder_path) if file_name.endswith('.xlsx') and (not file_name.startswith(\"~$\"))]\n",
    "\n",
    "# 정답률을 계산하기 위한 변수 초기화\n",
    "total_rows = 0\n",
    "correct_predictions = 0\n",
    "\n",
    "# 클래스 레이블을 추출합니다.\n",
    "class_labels = [\"front\", \"left_side\", \"right_side\", \"left_up\", \"left_down\", \"right_up\", \"right_down\", \"unknown\"]\n",
    "\n",
    "# 초기화: 정확한 예측 수를 누적할 딕셔너리\n",
    "correct_predictions_count = {label: 0 for label in class_labels}\n",
    "\n",
    "# 초기화: confusion matrix\n",
    "confusion_matrix_result = np.zeros((len(class_labels), len(class_labels)), dtype=float)  # 타입을 float로 변경\n",
    "\n",
    "# 각 파일별로 예측 실행 및 정확도 계산 및 컨퓨전 매트릭스 구성\n",
    "for excel_file in excel_files:\n",
    "    excel_file_path = os.path.join(folder_path, excel_file)\n",
    "\n",
    "    # 엑셀 파일 읽기\n",
    "    data_df = pd.read_excel(excel_file_path, engine='openpyxl')\n",
    "\n",
    "    for index, row in data_df.iloc[:].iterrows():\n",
    "        value_xx = row[\"xx\"] if \"xx\" in data_df.columns else row[0]\n",
    "        value_xy = row[\"xy\"] if \"xy\" in data_df.columns else row[1]\n",
    "        value_xz = row[\"xz\"] if \"xz\" in data_df.columns else row[2]\n",
    "        value_yx = row[\"yx\"] if \"yx\" in data_df.columns else row[3]\n",
    "        value_yy = row[\"yy\"] if \"yy\" in data_df.columns else row[4]\n",
    "        value_yz = row[\"yz\"] if \"yz\" in data_df.columns else row[5]\n",
    "        value_zx = row[\"zx\"] if \"zx\" in data_df.columns else row[6]\n",
    "        value_zy = row[\"zy\"] if \"zy\" in data_df.columns else row[7]\n",
    "        value_zz = row[\"zz\"] if \"zz\" in data_df.columns else row[8]\n",
    "\n",
    "        # 새로운 입력값을 2D 배열로 변환\n",
    "        new_input_data = np.array([value_xx, value_xy, value_xz, value_yx, value_yy, value_yz, value_zx, value_zy, value_zz])\n",
    "\n",
    "        # PCA 변환\n",
    "        new_input_3d = pca.transform(new_input_data.reshape(1, -1))  # 3D로 변환\n",
    "\n",
    "        # 모델을 활용하여 예측 수행\n",
    "        predicted_section = model.predict(new_input_3d)[0]\n",
    "\n",
    "        true_section_from_row = row.iloc[-1]\n",
    "\n",
    "        section_mapping = {\n",
    "            1: \"front\",\n",
    "            2: \"left_side\",\n",
    "            3: \"right_side\",\n",
    "            4: \"left_up\",\n",
    "            5: \"left_down\",\n",
    "            6: \"right_up\",\n",
    "            7: \"right_down\",\n",
    "        }\n",
    "\n",
    "        true_section_from_row = section_mapping.get(true_section_from_row, \"unknown\")\n",
    "\n",
    "        print(f\"File: {excel_file}, Row {index + 2} - Predicted section: {predicted_section}, True section: {true_section_from_row}\")\n",
    "\n",
    "        # 정확한 예측 수를 누적\n",
    "        if predicted_section == true_section_from_row:\n",
    "            correct_predictions_count[predicted_section] += 1\n",
    "\n",
    "        # 컨퓨전 매트릭스 업데이트\n",
    "        i = class_labels.index(true_section_from_row)\n",
    "        j = class_labels.index(predicted_section)\n",
    "        confusion_matrix_result[i, j] += 1\n",
    "\n",
    "        total_rows += 1\n",
    "\n",
    "        result_show += f\"\\nFile: {excel_file}, Row {index + 2} - Predicted section: {predicted_section}, True section: {true_section_from_row}\"\n",
    "\n",
    "    else:\n",
    "        print(\"No valid data to calculate accuracy.\")\n",
    "\n",
    "# 정확도 계산\n",
    "total_correct = sum(correct_predictions_count.values())\n",
    "accuracy = total_correct / total_rows\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import font_manager, rc\n",
    "rc('font', family='AppleGothic')\n",
    "\n",
    "# confusion matrix 시각화 (Seaborn을 사용하여 시각화)\n",
    "plt.figure(figsize=(20, 10),dpi=300)\n",
    "ax = sns.heatmap(confusion_matrix_result / confusion_matrix_result.sum(axis=1)[:, np.newaxis], annot=True, cmap='Blues', fmt='.2f',annot_kws={'size': 22})  # 비율로 변환, annot=True로 설정하여 셀에 숫자 표시, cmap은 색상 맵, fmt은 숫자 포맷 지정\n",
    "plt.xlabel('예측값',fontsize=20)\n",
    "plt.ylabel('실제값',fontsize=20)\n",
    "plt.title(\"K-means(pca5) 혼동행렬\",fontsize=22)\n",
    "\n",
    "class_labels = [\"IO\", \"LMO\", \"RMO\", \"LUMC\", \"LWMC\", \"RUMC\", \"RWMC\", \"unknown\"]\n",
    "\n",
    "# 셀과 셀 이름의 위치 맞추기\n",
    "ax.set_xticklabels(class_labels,rotation=0,fontsize=20)\n",
    "ax.set_yticklabels(class_labels,rotation=0,fontsize=20)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
